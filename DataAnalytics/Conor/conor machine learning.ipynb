{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import package pandas for data analysis\n",
    "import pandas as pd\n",
    "# Import package numpy for numeric computing\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "# Import package matplotlib for visualisation/plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from patsy import dmatrices\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pymysql\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#For showing plots directly in the notebook run the command below\n",
    "%matplotlib inline\n",
    "\n",
    "# For saving multiple plots into a single pdf file\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "import scipy.stats as ss\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('line_65_segments.csv', keep_default_na=True, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>DAYOFSERVICE</th>\n",
       "      <th>TRIPID</th>\n",
       "      <th>LINEID</th>\n",
       "      <th>PROGRNUMBER</th>\n",
       "      <th>STOPPOINTID</th>\n",
       "      <th>DIRECTION</th>\n",
       "      <th>ACTUALTIME_DEP</th>\n",
       "      <th>ACTUALTIME_ARR</th>\n",
       "      <th>hour</th>\n",
       "      <th>...</th>\n",
       "      <th>temp</th>\n",
       "      <th>pressure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_dir</th>\n",
       "      <th>sun</th>\n",
       "      <th>visibility</th>\n",
       "      <th>cloud_height</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>5956287</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>4521</td>\n",
       "      <td>1</td>\n",
       "      <td>34810</td>\n",
       "      <td>34797</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>240</td>\n",
       "      <td>0.2</td>\n",
       "      <td>30000</td>\n",
       "      <td>999</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>5956287</td>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "      <td>1283</td>\n",
       "      <td>1</td>\n",
       "      <td>34887</td>\n",
       "      <td>34887</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>240</td>\n",
       "      <td>0.2</td>\n",
       "      <td>30000</td>\n",
       "      <td>999</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>5956287</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>4456</td>\n",
       "      <td>1</td>\n",
       "      <td>34926</td>\n",
       "      <td>34926</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>240</td>\n",
       "      <td>0.2</td>\n",
       "      <td>30000</td>\n",
       "      <td>999</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>5956287</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>1284</td>\n",
       "      <td>1</td>\n",
       "      <td>34957</td>\n",
       "      <td>34948</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>240</td>\n",
       "      <td>0.2</td>\n",
       "      <td>30000</td>\n",
       "      <td>999</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>5956287</td>\n",
       "      <td>65</td>\n",
       "      <td>6</td>\n",
       "      <td>1285</td>\n",
       "      <td>1</td>\n",
       "      <td>35009</td>\n",
       "      <td>35009</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>240</td>\n",
       "      <td>0.2</td>\n",
       "      <td>30000</td>\n",
       "      <td>999</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738657</th>\n",
       "      <td>738657</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>8590288</td>\n",
       "      <td>65</td>\n",
       "      <td>75</td>\n",
       "      <td>7250</td>\n",
       "      <td>1</td>\n",
       "      <td>23204</td>\n",
       "      <td>23193</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>9.3</td>\n",
       "      <td>9.2</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30000</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738658</th>\n",
       "      <td>738658</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>8590288</td>\n",
       "      <td>65</td>\n",
       "      <td>76</td>\n",
       "      <td>7248</td>\n",
       "      <td>1</td>\n",
       "      <td>23349</td>\n",
       "      <td>23349</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>9.3</td>\n",
       "      <td>9.2</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30000</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738659</th>\n",
       "      <td>738659</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>8590288</td>\n",
       "      <td>65</td>\n",
       "      <td>77</td>\n",
       "      <td>7207</td>\n",
       "      <td>1</td>\n",
       "      <td>23418</td>\n",
       "      <td>23418</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>9.3</td>\n",
       "      <td>9.2</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30000</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738660</th>\n",
       "      <td>738660</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>8590288</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>7288</td>\n",
       "      <td>1</td>\n",
       "      <td>23520</td>\n",
       "      <td>23520</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>9.3</td>\n",
       "      <td>9.2</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30000</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738661</th>\n",
       "      <td>738661</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>8590297</td>\n",
       "      <td>65</td>\n",
       "      <td>77</td>\n",
       "      <td>7564</td>\n",
       "      <td>2</td>\n",
       "      <td>82984</td>\n",
       "      <td>82984</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>9.1</td>\n",
       "      <td>9.1</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30000</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>738338 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0 DAYOFSERVICE   TRIPID  LINEID  PROGRNUMBER  STOPPOINTID  \\\n",
       "0                0   2018-01-01  5956287      65            2         4521   \n",
       "1                1   2018-01-01  5956287      65            3         1283   \n",
       "2                2   2018-01-01  5956287      65            4         4456   \n",
       "3                3   2018-01-01  5956287      65            5         1284   \n",
       "4                4   2018-01-01  5956287      65            6         1285   \n",
       "...            ...          ...      ...     ...          ...          ...   \n",
       "738657      738657   2018-12-31  8590288      65           75         7250   \n",
       "738658      738658   2018-12-31  8590288      65           76         7248   \n",
       "738659      738659   2018-12-31  8590288      65           77         7207   \n",
       "738660      738660   2018-12-31  8590288      65           78         7288   \n",
       "738661      738661   2018-12-31  8590297      65           77         7564   \n",
       "\n",
       "        DIRECTION  ACTUALTIME_DEP  ACTUALTIME_ARR  hour  ...  temp  pressure  \\\n",
       "0               1           34810           34797     9  ...   4.6       7.1   \n",
       "1               1           34887           34887     9  ...   4.6       7.1   \n",
       "2               1           34926           34926     9  ...   4.6       7.1   \n",
       "3               1           34957           34948     9  ...   4.6       7.1   \n",
       "4               1           35009           35009     9  ...   4.6       7.1   \n",
       "...           ...             ...             ...   ...  ...   ...       ...   \n",
       "738657          1           23204           23193     6  ...   9.3       9.2   \n",
       "738658          1           23349           23349     6  ...   9.3       9.2   \n",
       "738659          1           23418           23418     6  ...   9.3       9.2   \n",
       "738660          1           23520           23520     6  ...   9.3       9.2   \n",
       "738661          2           82984           82984    23  ...   9.1       9.1   \n",
       "\n",
       "        humidity  wind_speed  wind_dir  sun visibility  cloud_height  \\\n",
       "0              7          14       240  0.2      30000           999   \n",
       "1              7          14       240  0.2      30000           999   \n",
       "2              7          14       240  0.2      30000           999   \n",
       "3              7          14       240  0.2      30000           999   \n",
       "4              7          14       240  0.2      30000           999   \n",
       "...          ...         ...       ...  ...        ...           ...   \n",
       "738657         9           7       230  0.0      30000            25   \n",
       "738658         9           7       230  0.0      30000            25   \n",
       "738659         9           7       230  0.0      30000            25   \n",
       "738660         9           7       230  0.0      30000            25   \n",
       "738661         9          11       250  0.0      30000            24   \n",
       "\n",
       "        cloud_cover  holiday  \n",
       "0                 3        1  \n",
       "1                 3        1  \n",
       "2                 3        1  \n",
       "3                 3        1  \n",
       "4                 3        1  \n",
       "...             ...      ...  \n",
       "738657            7        0  \n",
       "738658            7        0  \n",
       "738659            7        0  \n",
       "738660            7        0  \n",
       "738661            7        0  \n",
       "\n",
       "[738338 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segs_to_drop = list((df[\"segment_id\"].value_counts()[df[\"segment_id\"].value_counts() < 100]).index)\n",
    "\n",
    "df = df.query(f'segment_id not in {segs_to_drop}')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unrelated columns\n",
    "df = df.drop(columns=['Unnamed: 0',\"TRIPID\", \"LINEID\", \"STOPPOINTID\"])\n",
    "df[\"DIRECTION\"] = df[\"DIRECTION\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DAYOFSERVICE          360\n",
       "PROGRNUMBER            87\n",
       "DIRECTION               2\n",
       "ACTUALTIME_DEP      66252\n",
       "ACTUALTIME_ARR      66266\n",
       "hour                   22\n",
       "dayofweek               2\n",
       "journey_time         1788\n",
       "dwell_time            433\n",
       "prev_stop_id          184\n",
       "prev_progrnumber       87\n",
       "prev_dept_time      66096\n",
       "segment_id            187\n",
       "rain                   43\n",
       "temp                  294\n",
       "pressure              173\n",
       "humidity               19\n",
       "wind_speed             34\n",
       "wind_dir               36\n",
       "sun                    11\n",
       "visibility             55\n",
       "cloud_height           73\n",
       "cloud_cover             9\n",
       "holiday                 3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DAYOFSERVICE        0\n",
       "PROGRNUMBER         0\n",
       "DIRECTION           0\n",
       "ACTUALTIME_DEP      0\n",
       "ACTUALTIME_ARR      0\n",
       "hour                0\n",
       "dayofweek           0\n",
       "journey_time        0\n",
       "dwell_time          0\n",
       "prev_stop_id        0\n",
       "prev_progrnumber    0\n",
       "prev_dept_time      0\n",
       "segment_id          0\n",
       "rain                0\n",
       "temp                0\n",
       "pressure            0\n",
       "humidity            0\n",
       "wind_speed          0\n",
       "wind_dir            0\n",
       "sun                 0\n",
       "visibility          0\n",
       "cloud_height        0\n",
       "cloud_cover         0\n",
       "holiday             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if any null column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DAYOFSERVICE          object\n",
       "PROGRNUMBER            int64\n",
       "DIRECTION           category\n",
       "ACTUALTIME_DEP         int64\n",
       "ACTUALTIME_ARR         int64\n",
       "hour                   int64\n",
       "dayofweek              int64\n",
       "journey_time           int64\n",
       "dwell_time             int64\n",
       "prev_stop_id           int64\n",
       "prev_progrnumber       int64\n",
       "prev_dept_time         int64\n",
       "segment_id            object\n",
       "rain                 float64\n",
       "temp                 float64\n",
       "pressure             float64\n",
       "humidity               int64\n",
       "wind_speed             int64\n",
       "wind_dir               int64\n",
       "sun                  float64\n",
       "visibility             int64\n",
       "cloud_height           int64\n",
       "cloud_cover            int64\n",
       "holiday                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DAYOFSERVICE           int64\n",
       "PROGRNUMBER            int64\n",
       "DIRECTION           category\n",
       "ACTUALTIME_DEP         int64\n",
       "ACTUALTIME_ARR         int64\n",
       "hour                category\n",
       "dayofweek           category\n",
       "journey_time           int64\n",
       "dwell_time             int64\n",
       "prev_stop_id           int64\n",
       "prev_progrnumber       int64\n",
       "prev_dept_time         int64\n",
       "segment_id            object\n",
       "rain                 float64\n",
       "temp                 float64\n",
       "pressure             float64\n",
       "humidity               int64\n",
       "wind_speed             int64\n",
       "wind_dir               int64\n",
       "sun                  float64\n",
       "visibility             int64\n",
       "cloud_height           int64\n",
       "cloud_cover            int64\n",
       "holiday                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change datatypes of some features\n",
    "df['DAYOFSERVICE'] = df['DAYOFSERVICE'].astype('datetime64') #convert DAYOFSERVICE to datetime\n",
    "df['DAYOFSERVICE']=df['DAYOFSERVICE'].apply(lambda x: x.toordinal()) #then convert it to numeric\n",
    "df['dayofweek'] = df['dayofweek'].astype('category')\n",
    "df['hour'] = df['hour'].astype('category')\n",
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(df[\"journey_time\"])\n",
    "X = df.drop([\"journey_time\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original range is:  738338\n",
      "training range (70%):\t rows 0 to 516836\n",
      "test range (30%): \t rows 516836 to 738338\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into two datasets: 70% training and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=1)\n",
    "\n",
    "print(\"original range is: \",df.shape[0])\n",
    "print(\"training range (70%):\\t rows 0 to\", round(X_train.shape[0]))\n",
    "print(\"test range (30%): \\t rows\", round(X_train.shape[0]), \"to\", round(X_train.shape[0]) + X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DAYOFSERVICE          int64\n",
       "PROGRNUMBER           int64\n",
       "ACTUALTIME_DEP        int64\n",
       "ACTUALTIME_ARR        int64\n",
       "dwell_time            int64\n",
       "prev_stop_id          int64\n",
       "prev_progrnumber      int64\n",
       "prev_dept_time        int64\n",
       "rain                float64\n",
       "temp                float64\n",
       "pressure            float64\n",
       "humidity              int64\n",
       "wind_speed            int64\n",
       "wind_dir              int64\n",
       "sun                 float64\n",
       "visibility            int64\n",
       "cloud_height          int64\n",
       "cloud_cover           int64\n",
       "holiday               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuous_columns = X.select_dtypes(['int64','float64']).columns\n",
    "X[continuous_columns].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DIRECTION    category\n",
       "hour         category\n",
       "dayofweek    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns = df.select_dtypes(['category']).columns\n",
    "df[categorical_columns].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix using code found on https://stanford.edu/~mwaskom/software/seaborn/examples/many_pairwise_correlations.html\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "# Calculate correlation of all pairs of continuous features\n",
    "corr = X_train[continuous_columns].corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, annot=True, mask=mask, vmax=1, vmin=-1,\n",
    "            square=True, xticklabels=True, yticklabels=True,\n",
    "            linewidths=.5, cbar_kws={\"shrink\": .5}, ax=ax)\n",
    "plt.yticks(rotation = 0)\n",
    "plt.xticks(rotation = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict to hold correlation values \n",
    "corr_dict = {}\n",
    "\n",
    "# plot pairwise interaction between all continuous features and target\n",
    "for column in X_train[continuous_columns]:\n",
    "    # create temp df to merge column and target\n",
    "    df_temp = pd.concat([X_train[column], y_train], axis=1)\n",
    "    # store correlation in variable\n",
    "    correlation = df_temp[[column, \"journey_time\"]].corr().values[0,1]\n",
    "    # plot the column and tartget feature\n",
    "    df_temp.plot(kind='scatter', x=column, y=\"journey_time\", label=\"%.3f\" % correlation)\n",
    "    # add correlation to dict\n",
    "    corr_dict[column] = correlation\n",
    "\n",
    "# dataframe holding sorted correlation values to aid in interpreting results\n",
    "corr_df = pd.DataFrame.from_dict(corr_dict, orient='index', columns=['journey_time']).sort_values('journey_time', ascending=False)\n",
    "corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_information_gain = ['rain',\n",
    "                        'wind_dir',\n",
    "                        'cloud_cover',\n",
    "                        'wind_speed',\n",
    "                        'pressure',\n",
    "                        'humidity',\n",
    "                        'sun',\n",
    "                        \"PROGRNUMBER\",\n",
    "                        \"ACTUALTIME_DEP\",\n",
    "                        \"ACTUALTIME_ARR\",\n",
    "                        \"dwell_time\",\n",
    "                        \"prev_stop_id\",\n",
    "                        \"prev_progrnumber\",\n",
    "                        \"DAYOFSERVICE\",\n",
    "                        \"DIRECTION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "flierprops = dict(marker='o', markerfacecolor='green', markersize=6,\n",
    "                  linestyle='none')\n",
    "df.boxplot(column=['journey_time'], by=['dayofweek'], flierprops=flierprops, figsize=(10,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "flierprops = dict(marker='o', markerfacecolor='green', markersize=6,\n",
    "                  linestyle='none')\n",
    "df.boxplot(column=['journey_time'], by=['hour'], flierprops=flierprops, figsize=(10,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First attempt using one-hot encoding for the segment IDs\n",
    "This results in a very large number of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the useless column\n",
    "df_rev1 = df.copy()\n",
    "# drop low value features\n",
    "df_rev1.drop(low_information_gain, 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "journey_time              int64\n",
       "prev_dept_time            int64\n",
       "temp                    float64\n",
       "visibility                int64\n",
       "cloud_height              int64\n",
       "                         ...   \n",
       "segment_id_7287-7208      uint8\n",
       "segment_id_7288-7286      uint8\n",
       "segment_id_7289-7280      uint8\n",
       "segment_id_7395-6124      uint8\n",
       "segment_id_7564-4521      uint8\n",
       "Length: 217, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rev1 = pd.get_dummies(df_rev1)\n",
    "df_rev1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y is the target\n",
    "y = df_rev1[\"journey_time\"]\n",
    "# X is everything else\n",
    "X = df_rev1.drop([\"journey_time\"],1)\n",
    "# Split the dataset into two datasets: 70% training and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1,  test_size=0.3)\n",
    "\n",
    "print(\"original range is: \",df_rev1.shape[0])\n",
    "print(\"training range (70%):\\t rows 0 to\", round(X_train.shape[0]))\n",
    "print(\"test range (30%): \\t rows\", round(X_train.shape[0]), \"to\", round(X_train.shape[0]) + X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\nDescriptive features in X:\\n\", X_train.head(5))\n",
    "print(\"\\nTarget feature in y:\\n\", y_train.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to reset the index to allow contatenation with predicted values otherwise not joining on same index...\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)\n",
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train aka fit, a model using all continuous and categorical features.\n",
    "multiple_linreg = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the weights learned for each feature.\n",
    "print(\"\\nFeatures are: \\n\", X_train.columns)\n",
    "print(\"\\nCoeficients are: \\n\", multiple_linreg.coef_)\n",
    "print(\"\\nIntercept is: \\n\", multiple_linreg.intercept_)\n",
    "print(\"\\nFeatures and coeficients: \\n\", list(zip(X_train.columns, multiple_linreg.coef_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_linreg_predictions_train = multiple_linreg.predict(X_train)\n",
    "\n",
    "print(\"\\nPredictions with multiple linear regression: \\n\")\n",
    "actual_vs_predicted_multiplelinreg = pd.concat([y_train, pd.DataFrame(multiple_linreg_predictions_train, columns=['Predicted'])], axis=1)\n",
    "print(actual_vs_predicted_multiplelinreg.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is used repeatedly to compute all metrics\n",
    "def printMetrics(testActualVal, predictions):\n",
    "    #classification evaluation measures\n",
    "    print('\\n==============================================================================')\n",
    "    print(\"MAE: \", metrics.mean_absolute_error(testActualVal, predictions))\n",
    "    #print(\"MSE: \", metrics.mean_squared_error(testActualVal, predictions))\n",
    "    print(\"RMSE: \", metrics.mean_squared_error(testActualVal, predictions)**0.5)\n",
    "    print(\"R2: \", metrics.r2_score(testActualVal, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printMetrics(y_train, multiple_linreg_predictions_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_linreg_predictions_train = multiple_linreg.predict(X_test)\n",
    "\n",
    "print(\"\\nPredictions with multiple linear regression: \\n\")\n",
    "actual_vs_predicted_multiplelinreg = pd.concat([y_test, pd.DataFrame(multiple_linreg_predictions_train, columns=['Predicted'])], axis=1)\n",
    "print(actual_vs_predicted_multiplelinreg.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printMetrics(y_test, multiple_linreg_predictions_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = -cross_val_score(LinearRegression(), X, y, scoring='neg_mean_absolute_error', cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2']\n",
    "scores = cross_validate(LinearRegression(), X, y, scoring=metrics, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second attempt by creating individual models for each segment\n",
    "This means a large number of models will need to be created and stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rev2 = df.copy()\n",
    "# drop low value features\n",
    "df_rev2.drop(low_information_gain, 1, inplace=True)\n",
    "metrics_list = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2']\n",
    "results_dict = {\"MAE\": [],\n",
    "                \"RMSE\": [],\n",
    "                \"R2\": [],\n",
    "                \"cv_neg_mean_absolute_error\": [],\n",
    "                \"cv_neg_mean_squared_error\": [],\n",
    "                \"cv_r2\": []}\n",
    "\n",
    "segments = df.segment_id.unique()\n",
    "\n",
    "for i, seg in enumerate(segments):\n",
    "    print(i, seg)\n",
    "    seg_df = df_rev2.copy()\n",
    "    seg_df = seg_df[seg_df[\"segment_id\"] == seg]\n",
    "    seg_df.drop([\"segment_id\"], 1, inplace=True)\n",
    "    seg_df = pd.get_dummies(seg_df)\n",
    "\n",
    "    # y is the target\n",
    "    y = seg_df[\"journey_time\"]\n",
    "    # X is everything else\n",
    "    X = seg_df.drop([\"journey_time\"],1)\n",
    "    # Split the dataset into two datasets: 70% training and 30% test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1,  test_size=0.3)\n",
    "\n",
    "    # need to reset the index to allow contatenation with predicted values otherwise not joining on same index...\n",
    "    X_train.reset_index(drop=True, inplace=True)\n",
    "    y_train.reset_index(drop=True, inplace=True)\n",
    "    X_test.reset_index(drop=True, inplace=True)\n",
    "    y_test.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Train aka fit, a model using all continuous and categorical features.\n",
    "    multiple_linreg = LinearRegression().fit(X_train, y_train)\n",
    "    multiple_linreg_predictions_train = multiple_linreg.predict(X_train)\n",
    "    \n",
    "    results_dict[\"MAE\"].append(metrics.mean_absolute_error(y_train, multiple_linreg_predictions_train))\n",
    "    results_dict[\"RMSE\"].append(metrics.mean_squared_error(y_train, multiple_linreg_predictions_train)**0.5)\n",
    "    results_dict[\"R2\"].append(metrics.r2_score(y_train, multiple_linreg_predictions_train))\n",
    "                                           \n",
    "    actual_vs_predicted_multiplelinreg = pd.concat([y_train, pd.DataFrame(multiple_linreg_predictions_train, columns=['Predicted'])], axis=1)\n",
    "    print(actual_vs_predicted_multiplelinreg.head(10))\n",
    "    scores = cross_validate(LinearRegression(), X, y, scoring=metrics_list, cv=5)\n",
    "    for metric in metrics_list:\n",
    "        print( metric, np.average(scores[\"test_\" + metric]) )\n",
    "        results_dict[\"cv_\" + metric].append(np.average(scores[\"test_\" + metric]))\n",
    "    print(\"================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in results_dict:\n",
    "    results_dict[m] = np.average(results_dict[m])\n",
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "model=xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=42)\n",
    " \n",
    "# fit the model with the training data\n",
    "model.fit(X_train,y_train)\n",
    " \n",
    "predict_train = model.predict(X_train)\n",
    "print('\\nTarget on train data',predict_train) \n",
    " \n",
    "# Accuray Score on train dataset\n",
    "accuracy_train = accuracy_score(y_train,predict_train)\n",
    "print('\\naccuracy_score on train dataset : ', accuracy_train)\n",
    " \n",
    "# predict the target on the test dataset\n",
    "predict_test = model.predict(X_test)\n",
    "print('\\nTarget on test data',predict_test) \n",
    " \n",
    "# Accuracy Score on test dataset\n",
    "accuracy_test = accuracy_score(y_test,predict_test)\n",
    "print('\\naccuracy_score on test dataset : ', accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rev2 = df.copy()\n",
    "# drop low value features\n",
    "df_rev2.drop(low_information_gain, 1, inplace=True)\n",
    "metrics_list = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2']\n",
    "results_dict = {\"MAE\": [],\n",
    "                \"RMSE\": [],\n",
    "                \"R2\": [],\n",
    "                \"cv_neg_mean_absolute_error\": [],\n",
    "                \"cv_neg_mean_squared_error\": [],\n",
    "                \"cv_r2\": []}\n",
    "\n",
    "segments = df.segment_id.unique()\n",
    "\n",
    "for i, seg in enumerate(segments):\n",
    "    print(i, seg)\n",
    "    seg_df = df_rev2.copy()\n",
    "    seg_df = seg_df[seg_df[\"segment_id\"] == seg]\n",
    "    seg_df.drop([\"segment_id\"], 1, inplace=True)\n",
    "    seg_df = pd.get_dummies(seg_df)\n",
    "\n",
    "    # y is the target\n",
    "    y = seg_df[\"journey_time\"]\n",
    "    # X is everything else\n",
    "    X = seg_df.drop([\"journey_time\"],1)\n",
    "    # Split the dataset into two datasets: 70% training and 30% test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1,  test_size=0.3)\n",
    "\n",
    "    # need to reset the index to allow contatenation with predicted values otherwise not joining on same index...\n",
    "    X_train.reset_index(drop=True, inplace=True)\n",
    "    y_train.reset_index(drop=True, inplace=True)\n",
    "    X_test.reset_index(drop=True, inplace=True)\n",
    "    y_test.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Train aka fit, a model using all continuous and categorical features.\n",
    "    multiple_linreg = xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=42).fit(X_train, y_train)\n",
    "    multiple_linreg_predictions_train = multiple_linreg.predict(X_train)\n",
    "    \n",
    "    results_dict[\"MAE\"].append(metrics.mean_absolute_error(y_train, multiple_linreg_predictions_train))\n",
    "    results_dict[\"RMSE\"].append(metrics.mean_squared_error(y_train, multiple_linreg_predictions_train)**0.5)\n",
    "    results_dict[\"R2\"].append(metrics.r2_score(y_train, multiple_linreg_predictions_train))\n",
    "                                           \n",
    "    actual_vs_predicted_multiplelinreg = pd.concat([y_train, pd.DataFrame(multiple_linreg_predictions_train, columns=['Predicted'])], axis=1)\n",
    "    print(actual_vs_predicted_multiplelinreg.head(10))\n",
    "    scores = cross_validate(xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=42), X, y, scoring=metrics_list, cv=5)\n",
    "    for metric in metrics_list:\n",
    "        print( metric, np.average(scores[\"test_\" + metric]) )\n",
    "        results_dict[\"cv_\" + metric].append(np.average(scores[\"test_\" + metric]))\n",
    "    print(\"================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in results_dict:\n",
    "    results_dict[m] = np.average(results_dict[m])\n",
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "df_rev2 = df.copy()\n",
    "# drop low value features\n",
    "df_rev2.drop(low_information_gain, 1, inplace=True)\n",
    "metrics_list = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2']\n",
    "results_dict = {\"MAE\": [],\n",
    "                \"RMSE\": [],\n",
    "                \"R2\": [],\n",
    "                \"cv_neg_mean_absolute_error\": [],\n",
    "                \"cv_neg_mean_squared_error\": [],\n",
    "                \"cv_r2\": []}\n",
    "\n",
    "segments = df.segment_id.unique()\n",
    "\n",
    "for i, seg in enumerate(segments):\n",
    "    print(i, seg)\n",
    "    seg_df = df_rev2.copy()\n",
    "    seg_df = seg_df[seg_df[\"segment_id\"] == seg]\n",
    "    seg_df.drop([\"segment_id\"], 1, inplace=True)\n",
    "    seg_df = pd.get_dummies(seg_df)\n",
    "\n",
    "    # y is the target\n",
    "    y = seg_df[\"journey_time\"]\n",
    "    # X is everything else\n",
    "    X = seg_df.drop([\"journey_time\"],1)\n",
    "    # Split the dataset into two datasets: 70% training and 30% test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1,  test_size=0.3)\n",
    "\n",
    "    # need to reset the index to allow contatenation with predicted values otherwise not joining on same index...\n",
    "    X_train.reset_index(drop=True, inplace=True)\n",
    "    y_train.reset_index(drop=True, inplace=True)\n",
    "    X_test.reset_index(drop=True, inplace=True)\n",
    "    y_test.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Train aka fit, a model using all continuous and categorical features.\n",
    "    multiple_linreg = MLPRegressor(random_state=1, max_iter=300).fit(X_train, y_train)\n",
    "    multiple_linreg_predictions_train = multiple_linreg.predict(X_train)\n",
    "    \n",
    "    results_dict[\"MAE\"].append(metrics.mean_absolute_error(y_train, multiple_linreg_predictions_train))\n",
    "    results_dict[\"RMSE\"].append(metrics.mean_squared_error(y_train, multiple_linreg_predictions_train)**0.5)\n",
    "    results_dict[\"R2\"].append(metrics.r2_score(y_train, multiple_linreg_predictions_train))\n",
    "                                           \n",
    "    actual_vs_predicted_multiplelinreg = pd.concat([y_train, pd.DataFrame(multiple_linreg_predictions_train, columns=['Predicted'])], axis=1)\n",
    "    print(actual_vs_predicted_multiplelinreg.head(10))\n",
    "    scores = cross_validate(MLPRegressor(random_state=1, max_iter=300), X, y, scoring=metrics_list, cv=5)\n",
    "    for metric in metrics_list:\n",
    "        print( metric, np.average(scores[\"test_\" + metric]) )\n",
    "        results_dict[\"cv_\" + metric].append(np.average(scores[\"test_\" + metric]))\n",
    "    print(\"================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "df_rev2 = df.copy()\n",
    "# drop low value features\n",
    "df_rev2.drop(low_information_gain, 1, inplace=True)\n",
    "metrics_list = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2']\n",
    "results_dict = {\"MAE\": [],\n",
    "                \"RMSE\": [],\n",
    "                \"R2\": [],\n",
    "                \"cv_neg_mean_absolute_error\": [],\n",
    "                \"cv_neg_mean_squared_error\": [],\n",
    "                \"cv_r2\": []}\n",
    "\n",
    "segment_models = {}\n",
    "\n",
    "segments = df.segment_id.unique()\n",
    "\n",
    "for i, seg in enumerate(segments):\n",
    "    print(i, seg)\n",
    "    seg_df = df_rev2.copy()\n",
    "    seg_df = seg_df[seg_df[\"segment_id\"] == seg]\n",
    "    seg_df.drop([\"segment_id\"], 1, inplace=True)\n",
    "    seg_df = pd.get_dummies(seg_df)\n",
    "\n",
    "    # y is the target\n",
    "    y = seg_df[\"journey_time\"]\n",
    "    # X is everything else\n",
    "    X = seg_df.drop([\"journey_time\"],1)\n",
    "\n",
    "    # Train aka fit, a model using all continuous and categorical features.\n",
    "    segment_models[seg] = xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=42).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_models['4436-5008']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seg in segment_models:\n",
    "    with open(f'C:/Users/cls15/Google Drive/Comp Sci/Research Practicum/Code/dublin-bus-app/DataAnalytics/Conor/pickels/{seg}.pickle', 'wb') as f:\n",
    "        # Pickle the 'data' dictionary using the highest protocol available.\n",
    "        pickle.dump(segment_models[seg], f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seg in segment_models:\n",
    "    with open(f'C:/Users/cls15/Google Drive/Comp Sci/Research Practicum/Code/dublin-bus-app/DataAnalytics/Conor/pickels/{seg}.pickle', 'rb') as f:\n",
    "        data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = '4436-5008'\n",
    "seg_df = df_rev2.copy()\n",
    "seg_df = seg_df[seg_df[\"segment_id\"] == seg]\n",
    "seg_df.drop([\"segment_id\"], 1, inplace=True)\n",
    "seg_df = pd.get_dummies(seg_df)\n",
    "\n",
    "# y is the target\n",
    "y = seg_df[\"journey_time\"]\n",
    "# X is everything else\n",
    "X = seg_df.drop([\"journey_time\"],1)\n",
    "\n",
    "data.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>journey_time</th>\n",
       "      <th>prev_dept_time</th>\n",
       "      <th>segment_id</th>\n",
       "      <th>temp</th>\n",
       "      <th>visibility</th>\n",
       "      <th>cloud_height</th>\n",
       "      <th>holiday</th>\n",
       "      <th>predicted_journey</th>\n",
       "      <th>DAYOFSERVICE</th>\n",
       "      <th>PROGRNUMBER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>34667</td>\n",
       "      <td>7564-4521</td>\n",
       "      <td>4.6</td>\n",
       "      <td>30000</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>145.713287</td>\n",
       "      <td>736695</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>34810</td>\n",
       "      <td>4521-1283</td>\n",
       "      <td>4.6</td>\n",
       "      <td>30000</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>109.635406</td>\n",
       "      <td>736695</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>34887</td>\n",
       "      <td>1283-4456</td>\n",
       "      <td>4.6</td>\n",
       "      <td>30000</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>43.710220</td>\n",
       "      <td>736695</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>34926</td>\n",
       "      <td>4456-1284</td>\n",
       "      <td>4.6</td>\n",
       "      <td>30000</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>31.118746</td>\n",
       "      <td>736695</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>34957</td>\n",
       "      <td>1284-1285</td>\n",
       "      <td>4.6</td>\n",
       "      <td>30000</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>64.406311</td>\n",
       "      <td>736695</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738657</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>23153</td>\n",
       "      <td>4027-7250</td>\n",
       "      <td>9.3</td>\n",
       "      <td>30000</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>45.694683</td>\n",
       "      <td>737059</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738658</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>23204</td>\n",
       "      <td>7250-7248</td>\n",
       "      <td>9.3</td>\n",
       "      <td>30000</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>152.858292</td>\n",
       "      <td>737059</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738659</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>23349</td>\n",
       "      <td>7248-7207</td>\n",
       "      <td>9.3</td>\n",
       "      <td>30000</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>69.631256</td>\n",
       "      <td>737059</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738660</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>23418</td>\n",
       "      <td>7207-7288</td>\n",
       "      <td>9.3</td>\n",
       "      <td>30000</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>98.871460</td>\n",
       "      <td>737059</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738661</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>511</td>\n",
       "      <td>82473</td>\n",
       "      <td>1358-7564</td>\n",
       "      <td>9.1</td>\n",
       "      <td>30000</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>532.169373</td>\n",
       "      <td>737059</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>738338 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       hour dayofweek  journey_time  prev_dept_time segment_id  temp  \\\n",
       "0         9         0           130           34667  7564-4521   4.6   \n",
       "1         9         0            77           34810  4521-1283   4.6   \n",
       "2         9         0            39           34887  1283-4456   4.6   \n",
       "3         9         0            22           34926  4456-1284   4.6   \n",
       "4         9         0            52           34957  1284-1285   4.6   \n",
       "...     ...       ...           ...             ...        ...   ...   \n",
       "738657    6         0            40           23153  4027-7250   9.3   \n",
       "738658    6         0           145           23204  7250-7248   9.3   \n",
       "738659    6         0            69           23349  7248-7207   9.3   \n",
       "738660    6         0           102           23418  7207-7288   9.3   \n",
       "738661   23         0           511           82473  1358-7564   9.1   \n",
       "\n",
       "        visibility  cloud_height  holiday  predicted_journey  DAYOFSERVICE  \\\n",
       "0            30000           999        1         145.713287        736695   \n",
       "1            30000           999        1         109.635406        736695   \n",
       "2            30000           999        1          43.710220        736695   \n",
       "3            30000           999        1          31.118746        736695   \n",
       "4            30000           999        1          64.406311        736695   \n",
       "...            ...           ...      ...                ...           ...   \n",
       "738657       30000            25        0          45.694683        737059   \n",
       "738658       30000            25        0         152.858292        737059   \n",
       "738659       30000            25        0          69.631256        737059   \n",
       "738660       30000            25        0          98.871460        737059   \n",
       "738661       30000            24        0         532.169373        737059   \n",
       "\n",
       "        PROGRNUMBER  \n",
       "0                 2  \n",
       "1                 3  \n",
       "2                 4  \n",
       "3                 5  \n",
       "4                 6  \n",
       "...             ...  \n",
       "738657           75  \n",
       "738658           76  \n",
       "738659           77  \n",
       "738660           78  \n",
       "738661           77  \n",
       "\n",
       "[738338 rows x 12 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_prediction(segment, x):\n",
    "    with open(f'C:/Users/cls15/Google Drive/Comp Sci/Research Practicum/Code/dublin-bus-app/DataAnalytics/Conor/pickels/{segment}.pickle', 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "        return model.predict(x)\n",
    "\n",
    "data = pd.get_dummies(seg_df)\n",
    "seg = '4436-5008'\n",
    "seg_df = df_rev2.copy()\n",
    "seg_df = seg_df[seg_df[\"segment_id\"] == seg]\n",
    "seg_df.drop([\"segment_id\"], 1, inplace=True)\n",
    "seg_df = pd.get_dummies(seg_df)\n",
    "X = seg_df.drop([\"journey_time\"],1)\n",
    "get_prediction(seg, X.head(1))\n",
    "\n",
    "df_rev2 = df.copy()\n",
    "df_rev2.drop(low_information_gain, 1, inplace=True)\n",
    "predictions = {}\n",
    "for seg in df.segment_id.unique():\n",
    "    seg_df = df_rev2.copy()\n",
    "    seg_df = seg_df[seg_df[\"segment_id\"] == seg]\n",
    "    seg_df.drop([\"segment_id\"], 1, inplace=True)\n",
    "    seg_df = pd.get_dummies(seg_df)\n",
    "\n",
    "    # y is the target\n",
    "    y = seg_df[\"journey_time\"]\n",
    "    # X is everything else\n",
    "    X = seg_df.drop([\"journey_time\"],1)\n",
    "    seg_df[\"predicted_journey\"] = get_prediction(seg, X)\n",
    "    predictions[seg] = seg_df[\"predicted_journey\"]\n",
    "\n",
    "result = pd.concat(list(predictions.values()))\n",
    "\n",
    "df_rev2[\"predicted_journey\"] = 0\n",
    "\n",
    "df[[\"DAYOFSERVICE\",\"PROGRNUMBER\", ]]\n",
    "\n",
    "df_predictions = df_rev2.join(result) \n",
    "\n",
    "df_predictions.join(df[[\"DAYOFSERVICE\",\"PROGRNUMBER\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
